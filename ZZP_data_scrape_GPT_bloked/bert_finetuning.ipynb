{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "from transformers import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cfips</th>\n",
       "      <th>gpt_pro_1</th>\n",
       "      <th>gpt_pro_2</th>\n",
       "      <th>gpt_pro_3</th>\n",
       "      <th>gpt_con_1</th>\n",
       "      <th>gpt_con_2</th>\n",
       "      <th>gpt_con_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01001</td>\n",
       "      <td>Autauga County has a low cost of living, makin...</td>\n",
       "      <td>The county has a strong business community, pr...</td>\n",
       "      <td>Autauga County is located in the heart of Alab...</td>\n",
       "      <td>Autauga County has a relatively small populati...</td>\n",
       "      <td>The county has a limited number of resources a...</td>\n",
       "      <td>Autauga County is subject to the laws and regu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01003</td>\n",
       "      <td>Baldwin County has a strong economy with a low...</td>\n",
       "      <td>The cost of living is relatively low, making i...</td>\n",
       "      <td>There are numerous resources available to help...</td>\n",
       "      <td>The local government has strict regulations an...</td>\n",
       "      <td>The area is prone to natural disasters, such a...</td>\n",
       "      <td>There is a limited pool of skilled labor avail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01005</td>\n",
       "      <td>Low cost of living in Barbour County, Alabama,...</td>\n",
       "      <td>Access to a large customer base due to the cou...</td>\n",
       "      <td>Access to a variety of resources and support f...</td>\n",
       "      <td>Limited access to capital and financing option...</td>\n",
       "      <td>Lack of access to a skilled workforce due to t...</td>\n",
       "      <td>Limited access to technology and infrastructur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01007</td>\n",
       "      <td>Low cost of living in Bibb County, Alabama, ma...</td>\n",
       "      <td>Access to a large customer base due to the cou...</td>\n",
       "      <td>Access to a variety of resources and support f...</td>\n",
       "      <td>Limited access to capital and financing option...</td>\n",
       "      <td>Limited access to skilled labor due to the cou...</td>\n",
       "      <td>Limited access to technology and infrastructur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01009</td>\n",
       "      <td>Low cost of living in Blount County, Alabama, ...</td>\n",
       "      <td>Access to a large customer base due to the cou...</td>\n",
       "      <td>Access to resources such as the Blount County ...</td>\n",
       "      <td>Limited access to venture capital and other fo...</td>\n",
       "      <td>Limited access to skilled labor due to the cou...</td>\n",
       "      <td>Limited access to technology and other resourc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cfips                                          gpt_pro_1  \\\n",
       "0  01001  Autauga County has a low cost of living, makin...   \n",
       "1  01003  Baldwin County has a strong economy with a low...   \n",
       "2  01005  Low cost of living in Barbour County, Alabama,...   \n",
       "3  01007  Low cost of living in Bibb County, Alabama, ma...   \n",
       "4  01009  Low cost of living in Blount County, Alabama, ...   \n",
       "\n",
       "                                           gpt_pro_2  \\\n",
       "0  The county has a strong business community, pr...   \n",
       "1  The cost of living is relatively low, making i...   \n",
       "2  Access to a large customer base due to the cou...   \n",
       "3  Access to a large customer base due to the cou...   \n",
       "4  Access to a large customer base due to the cou...   \n",
       "\n",
       "                                           gpt_pro_3  \\\n",
       "0  Autauga County is located in the heart of Alab...   \n",
       "1  There are numerous resources available to help...   \n",
       "2  Access to a variety of resources and support f...   \n",
       "3  Access to a variety of resources and support f...   \n",
       "4  Access to resources such as the Blount County ...   \n",
       "\n",
       "                                           gpt_con_1  \\\n",
       "0  Autauga County has a relatively small populati...   \n",
       "1  The local government has strict regulations an...   \n",
       "2  Limited access to capital and financing option...   \n",
       "3  Limited access to capital and financing option...   \n",
       "4  Limited access to venture capital and other fo...   \n",
       "\n",
       "                                           gpt_con_2  \\\n",
       "0  The county has a limited number of resources a...   \n",
       "1  The area is prone to natural disasters, such a...   \n",
       "2  Lack of access to a skilled workforce due to t...   \n",
       "3  Limited access to skilled labor due to the cou...   \n",
       "4  Limited access to skilled labor due to the cou...   \n",
       "\n",
       "                                           gpt_con_3  \n",
       "0  Autauga County is subject to the laws and regu...  \n",
       "1  There is a limited pool of skilled labor avail...  \n",
       "2  Limited access to technology and infrastructur...  \n",
       "3  Limited access to technology and infrastructur...  \n",
       "4  Limited access to technology and other resourc...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "dtypes = {'cfips': str}\n",
    "df = pd.read_csv('gpt_pro_con_no_null.csv', dtype=dtypes)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_to_sentences(df):\n",
    "    docs = []\n",
    "    targets = []\n",
    "    for i in range(len(df)):\n",
    "        docs.append(df['gpt_pro_1'][i])\n",
    "        docs.append(df['gpt_pro_2'][i])\n",
    "        docs.append(df['gpt_pro_3'][i])\n",
    "        docs.append(df['gpt_con_1'][i])\n",
    "        docs.append(df['gpt_con_2'][i])\n",
    "        docs.append(df['gpt_con_3'][i])\n",
    "        targets.append(1)\n",
    "        targets.append(1)\n",
    "        targets.append(1)\n",
    "        targets.append(0)\n",
    "        targets.append(0)\n",
    "        targets.append(0)\n",
    "    return docs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs, targets = read_csv_to_sentences(df)\n",
    "final_sentences = docs\n",
    "final_targets = targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_sentences, test_sentences, train_labels, test_labels = train_test_split(final_sentences, final_targets, \n",
    "                                                                                test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer for distilbert\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "# MAX_LEN\n",
    "MAX_LEN = 256\n",
    "\n",
    "# BATCH_SIZE\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader\n",
    "class GPTCommentDataset(Dataset):\n",
    "    def __init__(self, sentences, targets, tokenizer, max_len):\n",
    "        self.sentences = sentences\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        sentence = str(self.sentences[item])\n",
    "        target = self.targets[item]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            sentence,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            pad_to_max_length=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "            truncation=True\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'sentence': sentence,\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'targets': torch.tensor(target, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "train_set = GPTCommentDataset(train_sentences, train_labels, tokenizer, MAX_LEN)\n",
    "test_set = GPTCommentDataset(test_sentences, test_labels, tokenizer, MAX_LEN)\n",
    "\n",
    "# data loader for train and test\n",
    "train_params = {'batch_size': BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "valid_params = {'batch_size': BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "train_dl = DataLoader(train_set, **train_params)\n",
    "valid_dl = DataLoader(test_set, **valid_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(nn.Module):\n",
    "    def __init__(self, checkpoint, freeze=False, device='cpu'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.device = device\n",
    "        self.model = DistilBertModel.from_pretrained(checkpoint)\n",
    "        if freeze:\n",
    "            i = 0\n",
    "            for layer in self.model.parameters():\n",
    "                i += 1\n",
    "                layer.requires_grad=False \n",
    "        # logistic regression\n",
    "        self.fc_1 = nn.Linear(768, 52)\n",
    "        self.relu_1 = nn.ReLU()\n",
    "        self.fc_2 = nn.Linear(52, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        \n",
    "    def forward(self, x, attention_mask=None):\n",
    "        model_out = self.model(x['input_ids'], x['attention_mask'], return_dict=True)\n",
    "        embds = model_out.last_hidden_state\n",
    "        mean_pool = embds.sum(axis=1) / x['attention_mask'].sum(axis=1).unsqueeze(axis=1)\n",
    "        extra_1 = self.relu_1(self.fc_1(mean_pool))\n",
    "        extra_2 = self.softmax(self.fc_2(extra_1))\n",
    "        return extra_2\n",
    "\n",
    "    def embedding(self, x, attention_mask=None):\n",
    "        model_out = self.model(x['input_ids'], x['attention_mask'], return_dict=True)\n",
    "        embds = model_out.last_hidden_state\n",
    "        mean_pool = embds.sum(axis=1) / x['attention_mask'].sum(axis=1).unsqueeze(axis=1)\n",
    "        extra_1 = self.relu_1(self.fc_1(mean_pool))\n",
    "        return extra_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model(\n",
       "  (model): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (activation): GELUActivation()\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (fc_1): Linear(in_features=768, out_features=52, bias=True)\n",
       "  (relu_1): ReLU()\n",
       "  (fc_2): Linear(in_features=52, out_features=2, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model\n",
    "checkpoint = 'distilbert-base-uncased'\n",
    "distilbert = model(checkpoint, freeze=False)\n",
    "distilbert.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fine tuning\n",
    "def train(model, train_dl, valid_dl, optimizer, criterion, epochs, device):\n",
    "    model = model.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        for batch in tqdm(train_dl):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(batch)\n",
    "            loss = criterion(output, batch['targets'])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            train_acc += (output.argmax(1) == batch['targets']).sum().item()\n",
    "        model.eval()\n",
    "        losses = []\n",
    "        accs = []\n",
    "        with torch.no_grad():\n",
    "            for batch in valid_dl:\n",
    "                output = model(batch)\n",
    "                loss = criterion(output, batch['targets'])\n",
    "                losses.append(loss.item())\n",
    "                accs.append((output.argmax(1) == batch['targets']).sum().item())\n",
    "        val_loss = np.mean(losses)\n",
    "        val_acc = np.mean(accs)\n",
    "        print(f'Epoch {epoch}, Train loss: {train_loss/len(train_dl):.3f}, Train acc: {train_acc/len(train_dl):.3f}')\n",
    "        print(f'Epoch {epoch}, Val loss: {val_loss:.3f}, Val acc: {val_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 943/943 [39:42<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Train loss: 0.320, Train acc: 15.918\n",
      "Epoch 0, Val loss: 0.314, Val acc: 15.975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 44/943 [01:55<39:19,  2.62s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m optimizer \u001b[39m=\u001b[39m AdamW(distilbert\u001b[39m.\u001b[39mparameters(), lr\u001b[39m=\u001b[39m\u001b[39m1e-5\u001b[39m)\n\u001b[1;32m      3\u001b[0m criterion \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m----> 4\u001b[0m train(distilbert, train_dl, valid_dl, optimizer, criterion, \u001b[39m2\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mcpu\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[19], line 11\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_dl, valid_dl, optimizer, criterion, epochs, device)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[39mfor\u001b[39;00m batch \u001b[39min\u001b[39;00m tqdm(train_dl):\n\u001b[1;32m     10\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 11\u001b[0m     output \u001b[39m=\u001b[39m model(batch)\n\u001b[1;32m     12\u001b[0m     loss \u001b[39m=\u001b[39m criterion(output, batch[\u001b[39m'\u001b[39m\u001b[39mtargets\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     13\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py39_PT_HF/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[17], line 20\u001b[0m, in \u001b[0;36mmodel.forward\u001b[0;34m(self, x, attention_mask)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, attention_mask\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> 20\u001b[0m     model_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x[\u001b[39m'\u001b[39;49m\u001b[39minput_ids\u001b[39;49m\u001b[39m'\u001b[39;49m], x[\u001b[39m'\u001b[39;49m\u001b[39mattention_mask\u001b[39;49m\u001b[39m'\u001b[39;49m], return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     21\u001b[0m     embds \u001b[39m=\u001b[39m model_out\u001b[39m.\u001b[39mlast_hidden_state\n\u001b[1;32m     22\u001b[0m     mean_pool \u001b[39m=\u001b[39m embds\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m) \u001b[39m/\u001b[39m x[\u001b[39m'\u001b[39m\u001b[39mattention_mask\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msum(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39munsqueeze(axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py39_PT_HF/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py39_PT_HF/lib/python3.9/site-packages/transformers/models/distilbert/modeling_distilbert.py:579\u001b[0m, in \u001b[0;36mDistilBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[39mif\u001b[39;00m inputs_embeds \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    578\u001b[0m     inputs_embeds \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membeddings(input_ids)  \u001b[39m# (bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m--> 579\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(\n\u001b[1;32m    580\u001b[0m     x\u001b[39m=\u001b[39;49minputs_embeds,\n\u001b[1;32m    581\u001b[0m     attn_mask\u001b[39m=\u001b[39;49mattention_mask,\n\u001b[1;32m    582\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    583\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    584\u001b[0m     output_hidden_states\u001b[39m=\u001b[39;49moutput_hidden_states,\n\u001b[1;32m    585\u001b[0m     return_dict\u001b[39m=\u001b[39;49mreturn_dict,\n\u001b[1;32m    586\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py39_PT_HF/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py39_PT_HF/lib/python3.9/site-packages/transformers/models/distilbert/modeling_distilbert.py:354\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[39mif\u001b[39;00m output_hidden_states:\n\u001b[1;32m    352\u001b[0m     all_hidden_states \u001b[39m=\u001b[39m all_hidden_states \u001b[39m+\u001b[39m (hidden_state,)\n\u001b[0;32m--> 354\u001b[0m layer_outputs \u001b[39m=\u001b[39m layer_module(\n\u001b[1;32m    355\u001b[0m     x\u001b[39m=\u001b[39;49mhidden_state, attn_mask\u001b[39m=\u001b[39;49mattn_mask, head_mask\u001b[39m=\u001b[39;49mhead_mask[i], output_attentions\u001b[39m=\u001b[39;49moutput_attentions\n\u001b[1;32m    356\u001b[0m )\n\u001b[1;32m    357\u001b[0m hidden_state \u001b[39m=\u001b[39m layer_outputs[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m    359\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py39_PT_HF/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py39_PT_HF/lib/python3.9/site-packages/transformers/models/distilbert/modeling_distilbert.py:289\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[39mParameters:\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[39m    x: torch.tensor(bs, seq_length, dim)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[39m    torch.tensor(bs, seq_length, dim) The output of the transformer block contextualization.\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[39m# Self-Attention\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m sa_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattention(\n\u001b[1;32m    290\u001b[0m     query\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m    291\u001b[0m     key\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m    292\u001b[0m     value\u001b[39m=\u001b[39;49mx,\n\u001b[1;32m    293\u001b[0m     mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[1;32m    294\u001b[0m     head_mask\u001b[39m=\u001b[39;49mhead_mask,\n\u001b[1;32m    295\u001b[0m     output_attentions\u001b[39m=\u001b[39;49moutput_attentions,\n\u001b[1;32m    296\u001b[0m )\n\u001b[1;32m    297\u001b[0m \u001b[39mif\u001b[39;00m output_attentions:\n\u001b[1;32m    298\u001b[0m     sa_output, sa_weights \u001b[39m=\u001b[39m sa_output  \u001b[39m# (bs, seq_length, dim), (bs, n_heads, seq_length, seq_length)\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py39_PT_HF/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/py39_PT_HF/lib/python3.9/site-packages/transformers/models/distilbert/modeling_distilbert.py:227\u001b[0m, in \u001b[0;36mMultiHeadSelfAttention.forward\u001b[0;34m(self, query, key, value, mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[39mif\u001b[39;00m head_mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    225\u001b[0m     weights \u001b[39m=\u001b[39m weights \u001b[39m*\u001b[39m head_mask\n\u001b[0;32m--> 227\u001b[0m context \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmatmul(weights, v)  \u001b[39m# (bs, n_heads, q_length, dim_per_head)\u001b[39;00m\n\u001b[1;32m    228\u001b[0m context \u001b[39m=\u001b[39m unshape(context)  \u001b[39m# (bs, q_length, dim)\u001b[39;00m\n\u001b[1;32m    229\u001b[0m context \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mout_lin(context)  \u001b[39m# (bs, q_length, dim)\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# fine tune distilbert\n",
    "optimizer = AdamW(distilbert.parameters(), lr=1e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train(distilbert, train_dl, valid_dl, optimizer, criterion, 2, 'cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Already really good, no need for more training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(distilbert.state_dict(), 'finetuned_distilbert.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class embedding_model(nn.Module):\n",
    "    def __init__(self, checkpoint, freeze=False, device='cpu'):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.device = device\n",
    "        self.model = DistilBertModel.from_pretrained(checkpoint)\n",
    "        if freeze:\n",
    "            i = 0\n",
    "            for layer in self.model.parameters():\n",
    "                i += 1\n",
    "                layer.requires_grad=False \n",
    "        # logistic regression\n",
    "        self.fc_1 = nn.Linear(768, 52)\n",
    "        self.relu_1 = nn.ReLU()\n",
    "        self.fc_2 = nn.Linear(52, 2)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "        \n",
    "    def forward(self, x, attention_mask=None):\n",
    "        model_out = self.model(x['input_ids'], x['attention_mask'], return_dict=True)\n",
    "        embds = model_out.last_hidden_state\n",
    "        mean_pool = embds.sum(axis=1) / x['attention_mask'].sum(axis=1).unsqueeze(axis=1)\n",
    "        extra_1 = self.relu_1(self.fc_1(mean_pool))\n",
    "        extra_2 = self.softmax(self.fc_2(extra_1))\n",
    "        return extra_2\n",
    "\n",
    "    def embedding_0(self, x, attention_mask=None):\n",
    "        model_out = self.model(x['input_ids'], x['attention_mask'], return_dict=True)\n",
    "        embds = model_out.last_hidden_state\n",
    "        mean_pool = embds.sum(axis=1) / x['attention_mask'].sum(axis=1).unsqueeze(axis=1)\n",
    "        return mean_pool\n",
    "\n",
    "    def embedding_1(self, x, attention_mask=None):\n",
    "        model_out = self.model(x['input_ids'], x['attention_mask'], return_dict=True)\n",
    "        embds = model_out.last_hidden_state\n",
    "        mean_pool = embds.sum(axis=1) / x['attention_mask'].sum(axis=1).unsqueeze(axis=1)\n",
    "        extra_1 = self.relu_1(self.fc_1(mean_pool))\n",
    "        return extra_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_projector.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "embedding_model = embedding_model(checkpoint, freeze=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load weights\n",
    "embedding_model.load_state_dict(torch.load('finetuned_distilbert.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get embeddings\n",
    "def get_embeddings_0(model, dl, device):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dl:\n",
    "            output = model.embedding_0(batch)\n",
    "            embeddings.append(output)\n",
    "    return embeddings\n",
    "\n",
    "def get_embeddings_1(model, dl, device):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dl:\n",
    "            output = model.embedding_1(batch)\n",
    "            embeddings.append(output)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset from final_sentences = docs\n",
    "docs, targets = read_csv_to_sentences(df)\n",
    "final_sentences = docs\n",
    "final_targets = targets\n",
    "\n",
    "data_set = GPTCommentDataset(final_sentences, final_targets, tokenizer, MAX_LEN)\n",
    "\n",
    "data_params = {'batch_size': BATCH_SIZE,\n",
    "                'shuffle': False,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "data_dl = DataLoader(data_set, **data_params)\n",
    "\n",
    "# get embeddings\n",
    "embeddings_0 = get_embeddings_0(embedding_model, data_dl, 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3142.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to numpy on all levels\n",
    "embeddings_0_np = []\n",
    "for i in range(len(embeddings_0)):\n",
    "    for emb in embeddings_0[i]:\n",
    "        embeddings_0_np.append(emb.numpy().tolist())\n",
    "\n",
    "len(embeddings_0_np) / 6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_0_list = embeddings_0_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3142.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_0_list) / 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_0_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('finetuned_distillBERT_embeddings.json', 'w') as f:\n",
    "    json.dump(embeddings_0_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_embeddings = []\n",
    "negative_embeddings = []\n",
    "for i in range(len(embeddings_0_list)):\n",
    "    if i % 6 == 0 or i % 6 == 1 or i % 6 == 2:\n",
    "        positive_embeddings.append(embeddings_0_list[i])\n",
    "    else:\n",
    "        negative_embeddings.append(embeddings_0_list[i])\n",
    "\n",
    "positive_sentences = []\n",
    "negative_sentences = []\n",
    "for i in range(len(final_sentences)):\n",
    "    if i % 6 == 0 or i % 6 == 1 or i % 6 == 2:\n",
    "        positive_sentences.append(final_sentences[i])\n",
    "    else:\n",
    "        negative_sentences.append(final_sentences[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Autauga County has a low cost of living, making it an affordable place to start a business.',\n",
       " 'The county has a strong business community, providing resources and support for entrepreneurs.',\n",
       " 'Autauga County is located in the heart of Alabama, providing easy access to major cities and transportation hubs.',\n",
       " 'Baldwin County has a strong economy with a low unemployment rate.',\n",
       " 'The cost of living is relatively low, making it an attractive place to start a business.',\n",
       " 'There are numerous resources available to help small businesses get started, such as the Small Business Development Center and the Baldwin County Economic Development Alliance.']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_sentences[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3142.0, 3142.0)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# set seed for the KMeans clustering\n",
    "np.random.seed(222)\n",
    "\n",
    "positive_clusterer = KMeans(n_clusters=10, verbose=0)\n",
    "positive_clustered_docs = positive_clusterer.fit_predict(positive_embeddings)\n",
    "\n",
    "negative_clusterer = KMeans(n_clusters=10, verbose=0)\n",
    "negative_clustered_docs = negative_clusterer.fit_predict(negative_embeddings)\n",
    "\n",
    "# positive cluster matric\n",
    "positive_cluster_labels = positive_clusterer.labels_\n",
    "positive_cluster_centers = positive_clusterer.cluster_centers_\n",
    "\n",
    "# negative cluster matric\n",
    "negative_cluster_labels = negative_clusterer.labels_\n",
    "negative_cluster_centers = negative_clusterer.cluster_centers_\n",
    "\n",
    "len(positive_cluster_labels)/3 , len(negative_cluster_labels)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_matched_list = list(zip(positive_sentences, positive_cluster_labels))\n",
    "negative_matched_list = list(zip(negative_sentences, negative_cluster_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_sentences(first, last, some_list, posi=True):\n",
    "    for i in range(first, last):\n",
    "        if posi:\n",
    "            print(f'Positive Cluster {i}:')\n",
    "        else:\n",
    "            print(f'Negative Cluster {i}:')\n",
    "        j = 0\n",
    "        for sentence, cluster in some_list:\n",
    "            if cluster == i:\n",
    "                print(sentence)\n",
    "                j += 1\n",
    "            if j == 12:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_cluster_names = {\n",
    "    0: 'Supportive_Community',\n",
    "    1: 'Low_Cost_of_Living',\n",
    "    2: 'Government_Support',\n",
    "    3: 'Large_Customer_Base',\n",
    "    4: 'Low_Cost_of_Living',\n",
    "    5: 'Low_Cost_of_Living',\n",
    "    6: 'Natural_Resources',\n",
    "    7: 'Connected_Economy',\n",
    "    8: 'Large_Customer_Base',\n",
    "    9: 'Government_Support'\n",
    "}\n",
    "\n",
    "negative_cluster_names = {\n",
    "    0: 'Limited_Tech_n_Infra',\n",
    "    1: 'Limited_Financing',\n",
    "    2: 'Tough_Labor_Market',\n",
    "    3: 'Various_Downsides',\n",
    "    4: 'Limited_Tech_n_Infra',\n",
    "    5: 'Tough_Labor_Market',\n",
    "    6: 'Low_Pop_Bad_Weather',\n",
    "    7: 'Limited_Financing',\n",
    "    8: 'Low_Pop_Bad_Weather',\n",
    "    9: 'Unfavorable_Location'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Cluster 0:\n",
      "The county has a strong business community, providing resources and support for entrepreneurs.\n",
      "Autauga County is located in the heart of Alabama, providing easy access to major cities and transportation hubs.\n",
      "Baldwin County has a strong economy with a low unemployment rate.\n",
      "There are numerous resources available to help small businesses get started, such as the Small Business Development Center and the Baldwin County Economic Development Alliance.\n",
      "Access to a large customer base due to the county's population of over 27,000 people.\n",
      "Access to a large customer base due to the county's proximity to Birmingham and other major cities.\n",
      "Access to a large customer base due to the county's population of over 57,000 people.\n",
      "Access to resources such as the Blount County Chamber of Commerce, which provides support and resources to local businesses.\n",
      "Access to resources such as the Small Business Development Center and the Butler County Chamber of Commerce\n",
      "Access to a large customer base due to the county's population of 118,572.\n",
      "Access to resources such as the Calhoun County Chamber of Commerce, which provides support and resources to small businesses.\n",
      "Access to resources such as the Chambers County Economic Development Council, which provides assistance to small businesses.\n",
      "Positive Cluster 1:\n",
      "Access to a large pool of potential customers\n",
      "Access to a large pool of potential employees\n",
      "Access to a wide range of natural resources\n",
      "Access to a wide range of natural resources\n",
      "Access to a wide range of natural resources\n",
      "Access to a wide range of natural resources\n",
      "Access to a wide range of natural resources\n",
      "Access to a wide range of natural resources\n",
      "Access to a wide range of natural resources\n",
      "Access to a wide variety of natural resources\n",
      "Access to a wide range of natural resources\n",
      "Access to a wide range of natural resources\n"
     ]
    }
   ],
   "source": [
    "get_cluster_sentences(0, 2, positive_matched_list, posi=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39_PT_HF",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af6b9edc317da9e350fdb877ab5f59b271488261a1f61deba33cb77ddc696fca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
